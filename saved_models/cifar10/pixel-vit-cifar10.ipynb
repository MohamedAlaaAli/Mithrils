{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.status.busy":"2024-08-25T16:50:11.767785Z","iopub.status.idle":"2024-08-25T16:50:11.768150Z","shell.execute_reply":"2024-08-25T16:50:11.767985Z","shell.execute_reply.started":"2024-08-25T16:50:11.767967Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, accuracy_score\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, random_split, Subset\n","import numpy as np\n","import random\n","from torch.utils.data import Dataset\n","from PIL import Image"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.status.busy":"2024-08-25T16:50:11.769704Z","iopub.status.idle":"2024-08-25T16:50:11.770055Z","shell.execute_reply":"2024-08-25T16:50:11.769899Z","shell.execute_reply.started":"2024-08-25T16:50:11.769881Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mohamed/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/mohamed/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}],"source":["model = torchvision.models.vit_b_16(pretrained=False)  "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.status.busy":"2024-08-25T16:50:11.770948Z","iopub.status.idle":"2024-08-25T16:50:11.771267Z","shell.execute_reply":"2024-08-25T16:50:11.771117Z","shell.execute_reply.started":"2024-08-25T16:50:11.771101Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [03:02<00:00, 935145.00it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/cifar-10-python.tar.gz to ../data\n","Files already downloaded and verified\n","Train size: 40000\n","Validation size: 10000\n","Test size: 10000\n"]}],"source":["# Set a seed for reproducibility\n","seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","\"\"\"torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\"\"\"\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),          \n","    transforms.RandomHorizontalFlip(),      \n","    transforms.RandomRotation(15),          \n","    transforms.ToTensor()                   \n","])\n","\n","test_val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),          \n","    transforms.ToTensor()                  \n","])\n","\n","# Load the full CIFAR-10 dataset\n","train_dataset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=train_transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=test_val_transform)\n","\n","# Split the training dataset into training and validation sets\n","train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(seed))\n","\n","# Apply the validation transform to the validation dataset\n","val_dataset.dataset.transform = test_val_transform\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Check the sizes\n","print(f\"Train size: {len(train_loader.dataset)}\")\n","print(f\"Validation size: {len(val_loader.dataset)}\")\n","print(f\"Test size: {len(test_loader.dataset)}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.status.busy":"2024-08-25T16:50:11.772259Z","iopub.status.idle":"2024-08-25T16:50:11.772638Z","shell.execute_reply":"2024-08-25T16:50:11.772447Z","shell.execute_reply.started":"2024-08-25T16:50:11.772429Z"},"trusted":true},"outputs":[],"source":["model.heads.head.out_features = 10"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.status.busy":"2024-08-25T16:50:11.773417Z","iopub.status.idle":"2024-08-25T16:50:11.773779Z","shell.execute_reply":"2024-08-25T16:50:11.773620Z","shell.execute_reply.started":"2024-08-25T16:50:11.773582Z"},"trusted":true},"outputs":[{"data":{"text/plain":["VisionTransformer(\n","  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","  (encoder): Encoder(\n","    (dropout): Dropout(p=0.0, inplace=False)\n","    (layers): Sequential(\n","      (encoder_layer_0): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_1): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_2): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_3): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_4): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_5): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_6): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_7): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_8): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_9): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_10): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_11): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (heads): Sequential(\n","    (head): Linear(in_features=768, out_features=10, bias=True)\n","  )\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-25T16:50:11.775330Z","iopub.status.idle":"2024-08-25T16:50:11.775684Z","shell.execute_reply":"2024-08-25T16:50:11.775510Z","shell.execute_reply.started":"2024-08-25T16:50:11.775493Z"},"trusted":true},"outputs":[],"source":["next(iter(train_loader))[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-25T16:50:11.776959Z","iopub.status.idle":"2024-08-25T16:50:11.777282Z","shell.execute_reply":"2024-08-25T16:50:11.777129Z","shell.execute_reply.started":"2024-08-25T16:50:11.777112Z"},"trusted":true},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T16:50:12.575429Z","iopub.status.busy":"2024-08-25T16:50:12.575059Z","iopub.status.idle":"2024-08-25T16:50:12.584235Z","shell.execute_reply":"2024-08-25T16:50:12.583384Z","shell.execute_reply.started":"2024-08-25T16:50:12.575387Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T12:37:55.209946Z","iopub.status.busy":"2024-08-25T12:37:55.209659Z","iopub.status.idle":"2024-08-25T12:37:55.218332Z","shell.execute_reply":"2024-08-25T12:37:55.217360Z","shell.execute_reply.started":"2024-08-25T12:37:55.209914Z"},"trusted":true},"outputs":[],"source":["num_epochs = 100\n","patience = 2  # Patience for early stopping\n","best_val_loss = np.inf\n","patience_counter = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T12:37:55.221632Z","iopub.status.busy":"2024-08-25T12:37:55.221316Z","iopub.status.idle":"2024-08-25T12:37:55.228128Z","shell.execute_reply":"2024-08-25T12:37:55.227358Z","shell.execute_reply.started":"2024-08-25T12:37:55.221600Z"},"trusted":true},"outputs":[],"source":["# Lists to store learning curve data\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","train_accuracies = []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T12:39:54.307333Z","iopub.status.busy":"2024-08-25T12:39:54.306424Z","iopub.status.idle":"2024-08-25T12:39:54.315385Z","shell.execute_reply":"2024-08-25T12:39:54.314492Z","shell.execute_reply.started":"2024-08-25T12:39:54.307290Z"},"trusted":true},"outputs":[],"source":["model= model.to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T12:37:55.333157Z","iopub.status.busy":"2024-08-25T12:37:55.332866Z","iopub.status.idle":"2024-08-25T12:37:55.342376Z","shell.execute_reply":"2024-08-25T12:37:55.341553Z","shell.execute_reply.started":"2024-08-25T12:37:55.333127Z"},"trusted":true},"outputs":[],"source":["# Define the training step function\n","def train_step(model, train_loader, optimizer, criterion):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in tqdm(train_loader, desc=\"Training\"):\n","        optimizer.zero_grad()\n","\n","        images = images.to(\"cuda\")\n","        labels = labels.to(\"cuda\")\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    avg_loss = running_loss / len(train_loader)\n","    accuracy = correct / total\n","    return avg_loss, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T12:37:55.344095Z","iopub.status.busy":"2024-08-25T12:37:55.343706Z","iopub.status.idle":"2024-08-25T12:37:55.351915Z","shell.execute_reply":"2024-08-25T12:37:55.350976Z","shell.execute_reply.started":"2024-08-25T12:37:55.344052Z"},"trusted":true},"outputs":[],"source":["# Define the validation step function\n","def val_step(model, val_loader, criterion):\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n","            images = images.to(\"cuda\")\n","            labels = labels.to(\"cuda\")\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","    val_accuracy = correct / total\n","    return avg_val_loss, val_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T12:39:56.755622Z","iopub.status.busy":"2024-08-25T12:39:56.755215Z","iopub.status.idle":"2024-08-25T12:40:17.304337Z","shell.execute_reply":"2024-08-25T12:40:17.302967Z","shell.execute_reply.started":"2024-08-25T12:39:56.755582Z"},"trusted":true},"outputs":[],"source":["for epoch in range(num_epochs):\n","    # Training step\n","    avg_train_loss, train_accuracy = train_step(model, train_loader, optimizer, criterion)\n","    train_losses.append(avg_train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy * 100:.2f}%\")\n","\n","    # Validation step\n","    avg_val_loss, val_accuracy = val_step(model, val_loader, criterion)\n","    val_losses.append(avg_val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n","\n","    # Early stopping check\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        patience_counter = 0\n","        # Save the best model checkpoint\n","        torch.save(model.state_dict(), \"best_model.pth\")\n","        print(\"Model saved.\")\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= patience:\n","            print(\"Early stopping triggered.\")\n","            break"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T12:39:56.755622Z","iopub.status.busy":"2024-08-25T12:39:56.755215Z","iopub.status.idle":"2024-08-25T12:40:17.304337Z","shell.execute_reply":"2024-08-25T12:40:17.302967Z","shell.execute_reply.started":"2024-08-25T12:39:56.755582Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Load the best model for evaluation\n","model.load_state_dict(torch.load(\"pixel-VIT-CIFAR10.pth\"))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T12:42:25.365930Z","iopub.status.busy":"2024-08-25T12:42:25.365550Z","iopub.status.idle":"2024-08-25T12:43:34.656434Z","shell.execute_reply":"2024-08-25T12:43:34.655077Z","shell.execute_reply.started":"2024-08-25T12:42:25.365896Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating Test Set: 100%|██████████| 157/157 [03:36<00:00,  1.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Accuracy 1: 0.96 and f1: 0.96\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Define the evaluation function\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    test_preds = []\n","    test_labels = []\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(test_loader, desc=\"Evaluating Test Set\"):\n","            images = images.to(\"cuda\")\n","            labels=labels.to(\"cuda\")\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            test_preds.extend(predicted.cpu().numpy())\n","            test_labels.extend(labels.cpu().numpy())\n","\n","    # Calculate F1 Score and Accuracy\n","    f1 = f1_score(test_labels, test_preds, average='weighted')\n","    accuracy = accuracy_score(test_labels, test_preds)\n","    return accuracy, f1\n","\n","accuracy1, f1 = evaluate_model(model.to(\"cuda\"), test_loader)\n","print(\"Accuracy 1: {:.2f} and f1: {:.2f}\".format(accuracy1, f1))\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}

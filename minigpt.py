# -*- coding: utf-8 -*-
"""minigpt (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zt3XI_zzJeAl5s9gOtMvz1HX8dMlZKI8
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install torch
!pip install torchaudio
!pip install torchvision
!pip install huggingface-hub
!pip install matplotlib
!pip install psutil
!pip install iopath
!pip install pyyaml
!pip install regex
!pip install tokenizers
!pip install tqdm
!pip install transformers
!pip install timm
!pip install webdataset
!pip install omegaconf
!pip install opencv-python
!pip install decord
!pip install peft
!pip install sentence-transformers
!pip install gradio
!pip install accelerate
!pip install bitsandbytes
!pip install scikit-image
!pip install visual-genome
!pip install wandb
!git clone https://github.com/MohamedAlaaAli/MiniGPT-4
# %cd MiniGPT-4

!sudo apt-get install git-lfs
!git lfs install
!git lfs install --skip-smudge
!git config filter.lfs.process = "git-lfs filter-process --skip"
!git config filter.lfs.smudge = "git-lfs smudge --skip -- %f"

#! git pull

!git lfs clone https://huggingface.co/Vision-CAIR/vicuna-7b

from google.colab import drive
drive.mount('/content/drive')

from PIL import Image
import torch
from torchvision import transforms

def load_img(img_path = '/content/panda.jpg'):

  image = Image.open(img_path).convert('RGB')

  transform = transforms.Compose([
      transforms.Resize((224, 224)),
      transforms.ToTensor(),
  ])

  image_tensor = transform(image)

  image_tensor = image_tensor.unsqueeze(0)

  return image_tensor

images = load_img()

texts = ["<Img><ImageHere></Img> Could you describe the contents of this image for me?"]

# Commented out IPython magic to ensure Python compatibility.
# %cd MiniGPT-4

import minigpt4.models.minigpt4 as minigpt4

def make_cfg(model_pth, ckpt_pth):
  cfg = {
    "vit_model": "eva_clip_g",
    "q_former_model": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xxl.pth",
    "image_size": 224,
    "num_query_token": 32,
    "llama_model": model_pth,
    "drop_path_rate": 0,
    "use_grad_checkpoint": False,
    "vit_precision": "fp32",
    "freeze_vit": True,
    "has_qformer": True,
    "freeze_qformer": True,
    "low_resource": True,
    "device_8bit": 0,
    "prompt_template": "<Img><ImageHere></Img> Could you describe the contents of this image for me?",
    "max_txt_len": 32,
    "end_sym": '\n',
    "ckpt": ckpt_pth
  }

  return cfg

cfg = make_cfg(model_pth="/content/MiniGPT-4/vicuna-7b", ckpt_pth="/content/drive/MyDrive/prerained_minigpt4_7b.pth")

# Clear CUDA memory cache
import gc
torch.cuda.empty_cache()
gc.collect()

if torch.cuda.is_available():
    total_memory = torch.cuda.get_device_properties(0).total_memory
    reserved_memory = torch.cuda.memory_reserved(0)
    allocated_memory = torch.cuda.memory_allocated(0)
    free_memory = total_memory - reserved_memory

    print(f"Total memory: {total_memory / (1024 ** 3):.2f} GB")
    print(f"Reserved memory: {reserved_memory / (1024 ** 3):.2f} GB")
    print(f"Allocated memory: {allocated_memory / (1024 ** 3):.2f} GB")
    print(f"Free memory: {free_memory / (1024 ** 3):.2f} GB")

model = minigpt4.MiniGPT4.from_config(cfg)

import shutil

source_file = '/content/vicuna-7b/pytorch_model-00001-of-00002.bin'
destination_directory = '/content/drive/My Drive/MiniGPT-4/vicuna-7b'

shutil.copy(source_file, destination_directory) # Use shutil.copy to copy a single file

images.shape

answers = model.generate(images, texts, max_new_tokens=300, do_sample=False,repetition_penalty=1.0)